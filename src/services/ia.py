import pandas as pd

def gerar_relatorio_com_busca_externa_stream(codSerie: str, dataframe: pd.DataFrame, callback=None):
    """
    Vers√£o com streaming e busca externa, que utiliza feedparser, da fun√ß√£o gerar_relatorio
    
    :param codSerie: C√≥digo da s√©rie do IPEA
    :param dataframe: DataFrame com os dados da s√©rie
    :param callback: Fun√ß√£o callback para receber o texto conforme √© gerado (opcional)
    :return: Texto completo do relat√≥rio
    """
    from together import Together
    import ipeadatapy as ip
    
    if dataframe.empty or codSerie == '':
        raise Exception("Parametros incorretos.")

    # Obter informa√ß√µes detalhadas da s√©rie
    try:
        descricaoSerie = ip.describe(codSerie)
        nomeSerie = descricaoSerie.iloc[0,0] if len(descricaoSerie) > 0 else "S√©rie n√£o identificada"
        comentarioSerie = descricaoSerie.iloc[6,0] if len(descricaoSerie) > 6 else "Coment√°rio n√£o dispon√≠vel"
        
        # Limpar dados vazios ou NaN e limitar coment√°rio a 150 caracteres
        if pd.isna(nomeSerie) or nomeSerie == "":
            nomeSerie = f"S√©rie {codSerie}"
        if pd.isna(comentarioSerie) or comentarioSerie == "":
            comentarioSerie = "Descri√ß√£o n√£o dispon√≠vel para esta s√©rie"
        else:
            comentarioSerie = comentarioSerie[:150]
            
        print(f"üìä S√©rie: {nomeSerie}")
        print(f"üìù Coment√°rio: {comentarioSerie[:100]}...")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao obter informa√ß√µes da s√©rie: {e}")
        nomeSerie = f"S√©rie {codSerie}"
        comentarioSerie = "Descri√ß√£o n√£o dispon√≠vel para esta s√©rie"

    dataframe = dataframe.sort_index(ascending=False)
    
    # Extrair apenas a coluna VALUE para otimizar o prompt (√≠ndice j√° cont√©m a data)
    try:
        # Verificar quantas colunas existem
        num_cols = len(dataframe.columns)
        print(f"üìä DataFrame: {dataframe.shape} colunas - {list(dataframe.columns)}")
        
        # Usar a √∫ltima coluna como VALUE (geralmente √© a coluna de valores)
        value_col_idx = num_cols - 1
        
        # Extrair os √∫ltimos 300 registros com a coluna de valores
        # O √≠ndice j√° cont√©m a informa√ß√£o de data
        df_otimizado = dataframe.iloc[:300, [value_col_idx]].copy()
        
        # Renomear a coluna para facilitar leitura
        df_otimizado.columns = ['Valor']
        csv_text = df_otimizado.to_csv(index=True)  # Mant√©m o √≠ndice (data)
        print(f"‚úÖ CSV otimizado gerado com {len(df_otimizado)} linhas - apenas coluna Valor + √≠ndice de data")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro na otimiza√ß√£o do CSV: {e}")
        # Fallback seguro: usar todo o DataFrame limitado
        csv_text = dataframe.head(50).to_csv(index=True)
    
    # Busca externa por not√≠cias (mesma l√≥gica da fun√ß√£o original)
    def buscar_noticias_google(query):
        try:
            import feedparser
            url = f"https://news.google.com/rss/search?q={query.replace(' ', '+')}&hl=pt-BR&gl=BR&ceid=BR:pt"
            feed = feedparser.parse(url)
            
            noticias = []
            for entry in feed.entries[:5]:
                noticias.append({
                    'titulo': entry.title,
                    'link': entry.link,
                    'data': entry.published if hasattr(entry, 'published') else 'N/A',
                    'resumo': entry.summary if hasattr(entry, 'summary') else 'N/A'
                })
            
            return noticias
        except Exception as e:
            print(f"Erro ao buscar not√≠cias: {e}")
            return []
    
    # Busca not√≠cias relacionadas
    termos_busca = [
        f"IPEA {codSerie}",
        f"{nomeSerie} Brasil",
        f"economia brasileira {nomeSerie.split()[-1] if nomeSerie else 'indicadores'}",
        "dados econ√¥micos Brasil IPEA",
        f"an√°lise econ√¥mica {nomeSerie.split()[0] if nomeSerie else 'atual'}"
    ]
    
    todas_noticias = []
    for termo in termos_busca:
        noticias = buscar_noticias_google(termo)
        todas_noticias.extend(noticias)
    
    # Formata as not√≠cias para incluir no prompt (vers√£o resumida)
    contexto_noticias = ""
    if todas_noticias:
        contexto_noticias = f"\n\nNOT√çCIAS RELACIONADAS √Ä S√âRIE '{nomeSerie}':\n"
        for i, noticia in enumerate(todas_noticias[:5], 1):  # Apenas 5 not√≠cias
            contexto_noticias += f"{i}. {noticia['titulo'][:100]}...\n"  # T√≠tulo limitado a 100 chars
    else:
        contexto_noticias = f"\n\nNOTA: An√°lise baseada no contexto econ√¥mico brasileiro atual.\n"
    
    prompt = f"""Analise esta s√©rie temporal financeira real do IPEA e responda EXCLUSIVAMENTE EM PORTUGU√äS BRASILEIRO:

    S√âRIE: {codSerie} - {nomeSerie}

    Gere uma an√°lise profissional em portugu√™s brasileiro abordando:
    1. Resumo da s√©rie temporal observada
    2. Tend√™ncia observada (crescimento, queda, estabilidade)
    3. Principais eventos que influenciaram os dados
    4. Anomalias e poss√≠veis causas
    5. Implica√ß√µes para investidores/formuladores de pol√≠ticas
    6. Sugest√µes de a√ß√£o
    7. Empresas brasileiras do setor (se aplic√°vel)
    8. Correla√ß√£o com as not√≠cias fornecidas

    IMPORTANTE: Responda APENAS em portugu√™s brasileiro, sem usar express√µes em ingl√™s.

    Dados da s√©rie (CSV):
    {csv_text}
    
    {contexto_noticias}
    """
    
    try:
        client = Together(api_key='31c6c1ddf940cd1ac1ad20db676e21745a49f1975e5913ec4ecfac8969c431ab')
        
        # Fazer streaming da resposta
        stream = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
            messages=[
                {
                    "role": "user",
                    "content": prompt,
                }
            ],
            max_tokens=4000,
            temperature=0.7,
            stream=True  # Habilita streaming
        )
        
        full_text = ""
        thinking_buffer = ""
        in_thinking = False
        
        for chunk in stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                
                # Filtrar tags <think> em tempo real
                for char in content:
                    if char == '<' and not in_thinking:
                        thinking_buffer = '<'
                    elif in_thinking:
                        thinking_buffer += char
                        if thinking_buffer.endswith('</think>'):
                            in_thinking = False
                            thinking_buffer = ""
                    elif thinking_buffer:
                        thinking_buffer += char
                        if thinking_buffer == '<think>':
                            in_thinking = True
                            thinking_buffer = ""
                        elif not thinking_buffer.startswith('<'):
                            # N√£o √© tag <think>, adicionar ao texto
                            text_to_add = thinking_buffer
                            # Escapar $ para evitar modo matem√°tico do Markdown
                            text_to_add = text_to_add.replace('$', '\\$')
                            full_text += text_to_add
                            if callback:
                                callback(text_to_add)
                            thinking_buffer = ""
                            thinking_buffer += char
                    else:
                        # Escapar $ para evitar modo matem√°tico do Markdown
                        escaped_char = char.replace('$', '\\$')
                        full_text += escaped_char
                        if callback:
                            callback(escaped_char)
        
        return full_text.strip()
        
    except Exception as e:
        print(f"Erro detalhado: {e}")
        raise Exception("Conex√£o com IA falhou.")